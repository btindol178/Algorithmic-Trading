{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btindol\\OneDrive - Stryker\\Linked In Learn\\Algorithmic Investing\\Algorithmic Trading & Quantitative Analysis using Python\n",
      "Requirement already satisfied: datetime in c:\\users\\btindol\\anaconda3\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\btindol\\anaconda3\\lib\\site-packages (from datetime) (5.1.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\btindol\\anaconda3\\lib\\site-packages (from datetime) (2020.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\btindol\\anaconda3\\lib\\site-packages (from zope.interface->datetime) (50.3.1.post20201107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\btindol\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stocktrends in c:\\users\\btindol\\anaconda3\\lib\\site-packages (0.1.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\btindol\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\btindol\\\\OneDrive - Stryker\\\\Linked In Learn\\\\Algorithmic Investing\\Algorithmic Trading & Quantitative Analysis using Python')  \n",
    "print(os.getcwd())  # Prints the current working directory\n",
    "\n",
    "#####################################################################################################################################################\n",
    "#imports \n",
    "#!pip install yfinance \n",
    "#!pip install pandas \n",
    "#!pip install numpy\n",
    "#!pip install requests\n",
    "!pip install datetime\n",
    "#!pip install yahoofinancials\n",
    "!pip install stocktrends\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime as dt\n",
    "import os\n",
    "import json \n",
    "from functools import reduce\n",
    "import statsmodels.api as sm\n",
    "from stocktrends import Renko\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE STOCK ANALYZER NOW MAKE STRATEGY OFF OF IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['ETH-USD']\n",
    "end_date = (dt.date.today()).strftime('%Y-%m-%d')\n",
    "beg_date = (dt.date.today()-dt.timedelta(1825)).strftime('%Y-%m-%d') # 1825 is 5 years ish \n",
    "\n",
    "\n",
    "# Used to make a dataframe of percent change from the daily price data!!!\n",
    "def get_daily_returns(df):\n",
    "    daily_return = df.pct_change()\n",
    "    cols = daily_return.columns.tolist()\n",
    "    newcols = []\n",
    "    for j in range(0,len(cols)):\n",
    "        colz = cols[j] + \"_\" + \"percent_change\"\n",
    "\n",
    "        newcols.append(colz)\n",
    "    daily_return.columns = newcols               \n",
    "    return daily_return\n",
    "\n",
    "# Calculating RSI without using loop\n",
    "def rsi(df, n):\n",
    "    \"function to calculate RSI\"\n",
    "    delta = df.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[n-1]] = np.mean( u[:n])                                            # first value is average of gains\n",
    "    u = u.drop(u.index[:(n-1)])\n",
    "    d[d.index[n-1]] = np.mean( d[:n])                                             # first value is average of losses\n",
    "    d = d.drop(d.index[:(n-1)])\n",
    "    rs = u.ewm(com=n,min_periods=n).mean()/d.ewm(com=n,min_periods=n).mean()\n",
    "    return 100 - 100 / (1+rs)\n",
    "\n",
    "def ATR(n):\n",
    "    DF = yf.download(ticker,beg_date,end_date)[[\"Open\",\"High\",\"Low\",\"Adj Close\",\"Volume\"]]\n",
    "    \"function to calculate True Range and Average True Range\"\n",
    "    df = DF.copy()\n",
    "    df['H-L']=abs(df['High']-df['Low'])\n",
    "    df['H-PC']=abs(df['High']-df['Adj Close'].shift(1))\n",
    "    df['L-PC']=abs(df['Low']-df['Adj Close'].shift(1))\n",
    "    df['TR']=df[['H-L','H-PC','L-PC']].max(axis=1,skipna=False)\n",
    "    #df['ATR'] = df['TR'].rolling(n).mean()\n",
    "    df['ATR'] = df['TR'].ewm(span=n,adjust=False,min_periods=n).mean() # 14 periods exponential weighted moving average to measure longer volitility use 90 day\n",
    "    df2 = df.drop(['H-L','H-PC','L-PC'],axis=1)\n",
    "    return df2[['Open','High','Low','ATR','TR']]\n",
    "\n",
    "def ADX(DF,n):\n",
    "    \"function to calculate ADX\"\n",
    "    df2 = DF.copy()\n",
    "    df2['TR'] = ATR(n)['TR'] #the period parameter of ATR function does not matter because period does not influence TR calculation\n",
    "    df2['DMplus']=np.where((df2['High']-df2['High'].shift(1))>(df2['Low'].shift(1)-df2['Low']),df2['High']-df2['High'].shift(1),0)\n",
    "    df2['DMplus']=np.where(df2['DMplus']<0,0,df2['DMplus'])\n",
    "    df2['DMminus']=np.where((df2['Low'].shift(1)-df2['Low'])>(df2['High']-df2['High'].shift(1)),df2['Low'].shift(1)-df2['Low'],0)\n",
    "    df2['DMminus']=np.where(df2['DMminus']<0,0,df2['DMminus'])\n",
    "    TRn = []\n",
    "    DMplusN = []\n",
    "    DMminusN = []\n",
    "    TR = df2['TR'].tolist()\n",
    "    DMplus = df2['DMplus'].tolist()\n",
    "    DMminus = df2['DMminus'].tolist()\n",
    "    for i in range(len(df2)):\n",
    "        if i < n:\n",
    "            TRn.append(np.NaN)\n",
    "            DMplusN.append(np.NaN)\n",
    "            DMminusN.append(np.NaN)\n",
    "        elif i == n:\n",
    "            TRn.append(df2['TR'].rolling(n).sum().tolist()[n])\n",
    "            DMplusN.append(df2['DMplus'].rolling(n).sum().tolist()[n])\n",
    "            DMminusN.append(df2['DMminus'].rolling(n).sum().tolist()[n])\n",
    "        elif i > n:\n",
    "            TRn.append(TRn[i-1] - (TRn[i-1]/n) + TR[i])\n",
    "            DMplusN.append(DMplusN[i-1] - (DMplusN[i-1]/n) + DMplus[i])\n",
    "            DMminusN.append(DMminusN[i-1] - (DMminusN[i-1]/n) + DMminus[i])\n",
    "    df2['TRn'] = np.array(TRn)\n",
    "    df2['DMplusN'] = np.array(DMplusN)\n",
    "    df2['DMminusN'] = np.array(DMminusN)\n",
    "    df2['DIplusN']=100*(df2['DMplusN']/df2['TRn'])\n",
    "    df2['DIminusN']=100*(df2['DMminusN']/df2['TRn'])\n",
    "    df2['DIdiff']=abs(df2['DIplusN']-df2['DIminusN'])\n",
    "    df2['DIsum']=df2['DIplusN']+df2['DIminusN']\n",
    "    df2['DX']=100*(df2['DIdiff']/df2['DIsum'])\n",
    "    ADX = []\n",
    "    DX = df2['DX'].tolist()\n",
    "    for j in range(len(df2)):\n",
    "        if j < 2*n-1:\n",
    "            ADX.append(np.NaN)\n",
    "        elif j == 2*n-1:\n",
    "            ADX.append(df2['DX'][j-n+1:j+1].mean())\n",
    "        elif j > 2*n-1:\n",
    "            ADX.append(((n-1)*ADX[j-1] + DX[j])/n)\n",
    "    df2['ADX']=np.array(ADX)\n",
    "    return df2['ADX']\n",
    "\n",
    "\n",
    "def MACD(DF,a,b,c):\n",
    "    \"\"\"function to calculate MACD\n",
    "       typical values a = 12; b =26, c =9\"\"\"\n",
    "    df = DF.copy()\n",
    "    df[\"MA_Fast\"]=final_f.iloc[:,0].ewm(span=a,min_periods=a).mean()\n",
    "    df[\"MA_Slow\"]=final_f.iloc[:,0].ewm(span=b,min_periods=b).mean()\n",
    "    df[\"MACD\"]=df[\"MA_Fast\"]-df[\"MA_Slow\"]\n",
    "    df[\"Signal\"]=df[\"MACD\"].ewm(span=c,min_periods=c).mean()\n",
    "    df.dropna(inplace=True)\n",
    "    return df[['MACD','Signal']]\n",
    "\n",
    "\n",
    "def single_stock_analyzer(stocks, begin_date,end_date,initial_position,slow_ma,fast_ma):\n",
    "    cl_price = pd.DataFrame()\n",
    "\n",
    "    # looping over tickers and creating a dataframe with closing prices\n",
    "    for ticker in stocks:\n",
    "        cl_price[ticker] = yf.download(ticker,beg_date,end_date)['Adj Close']     # get just adjusted close column\n",
    "\n",
    "    cl_price_plus_ret = get_daily_returns(cl_price)\n",
    "    final = cl_price.merge(cl_price_plus_ret, on='Date', how='left')\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # for each of the column names for the % change columns \n",
    "    pctchg = [col for col in cl_price_plus_ret.columns if 'percent_change' in col] # grabe % change columns\n",
    "    colnew = []                                                                    # initiate empty list\n",
    "    for i in range(0,len(pctchg)):                                                 # loop over column names\n",
    "        print(pctchg[i])\n",
    "        var1 = cl_price_plus_ret[pctchg[i]].shift(-1)                                      # grab colunmn by name and shift up one\n",
    "        colnew.append(var1)                                                        # append to list\n",
    "    colnew = pd.DataFrame(colnew)                                                  # now its wide dataframe\n",
    "    colnew = colnew.transpose()                                                    # make it narrow\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    cols = colnew.columns.tolist()                                                 # take column names of narrow dataframe                                                \n",
    "    newcols = []                                                                   # make list to add the text shift to the column name\n",
    "    for j in range(0,len(cols)): \n",
    "        colz = cols[j] + \"_\" + \"shift\"                                             # add shift to the name of shifted column\n",
    "           \n",
    "        newcols.append(colz) \n",
    "    colnew.columns = newcols                                                       # assign the new shifted columns to origional\n",
    "    \n",
    "    final_f= final.merge(colnew, on='Date', how='left')\n",
    "\n",
    "    final_f =final_f.fillna(0)     \n",
    "    # fill na\n",
    "    final_f.columns = final_f.columns.str.replace(\"-\", \"_\")                         # replace all innapropriate characthers with  underscores in column names\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # Calculate returns from initial position entry \n",
    "    shiftval = [col for col in final_f.columns if 'shift' in col]                   # find the shift column to bring % change up to today to mutliply to get positions next day amount.. \n",
    "    \n",
    "    initial_position = initial_position                                             # pass from function above\n",
    "    \n",
    "    new = [(final_f[shiftval[0]][0] * initial_position) + initial_position]        # get first value in final for iterate the 0 of this \n",
    "    for i in range(1, len(final_f.index)):                                          # starting at second row of the dataframe column \n",
    "        new.append((new[i-1]*final_f[shiftval].values[i][0]) +new[i-1])\n",
    "\n",
    "    final_f['Position'] = new\n",
    "    final_f['Position'] = final_f['Position'].shift(1)\n",
    "    final_f['Position'][0] = initial_position\n",
    "    final_f.fillna(0)\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # Try to figure out how to call out by name here... for multiple stocks \n",
    "    final_f['Fast_moving_average'] = final_f.iloc[:,0].rolling(window=fast_ma).mean() # 5 day price moving average\n",
    "    final_f['Slow_moving_average'] = final_f.iloc[:,0].rolling(window=slow_ma).mean() # 5 day price moving average\n",
    "\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # Bolligner band of the fast moving average 30 day.. \n",
    "    final_f[\"BB_up\"] = final_f[\"Fast_moving_average\"] + 2*final_f.iloc[:,0].rolling(fast_ma).std(ddof=0) #ddof=0 is required since we want to take the standard deviation of the population and not sample\n",
    "    final_f[\"BB_dn\"] = final_f[\"Fast_moving_average\"] - 2*final_f.iloc[:,0].rolling(fast_ma).std(ddof=0) #ddof=0 is required since we want to take the standard deviation of the population and not sample\n",
    "    final_f[\"BB_width\"] = final_f[\"BB_up\"] - final_f[\"BB_dn\"]\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # RSI\n",
    "    # What Is the Relative Strength Index (RSI)?\n",
    "    # The relative strength index (RSI) is a momentum indicator used in technical analysis that\n",
    "    #measures the magnitude of recent price changes to evaluate overbought or oversold conditions in\n",
    "    #the price of a stock or other asset. \n",
    "    #The RSI is displayed as an oscillator (a line graph that moves between two extremes) and can have a\n",
    "    #reading from 0 to 100. The indicator was originally developed by J. Welles Wilder Jr. and introduced in his seminal 1978 book,\n",
    "    #\"New Concepts in Technical Trading Systems.\"\n",
    "    # Traditional interpretation and usage of the RSI are that values of 70 or above indicate that a security is becoming overbought\n",
    "    #or overvalued and may be primed for a trend reversal or corrective pullback in price. An RSI reading of 30 or below indicates\n",
    "    #an oversold or undervalued condition.\n",
    "    final_f[\"RSI_slow\"] = rsi(final_f.iloc[:,0],slow_ma) # look at last values using slow as window\n",
    "    final_f[\"RSI_fast\"] = rsi(final_f.iloc[:,0],fast_ma)\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # ATR \n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #  To measure recent volatility, use a shorter average, such as 2 to 10 periods. For longer-term volatility, use 20 to 50 periods.\n",
    "    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/atr\n",
    "    #Average True Range (ATR) is the average of true ranges over the specified period.\n",
    "    #ATR measures volatility, taking into account any gaps in the price movement. \n",
    "    #Typically, the ATR calculation is based on 14 periods, which can be intraday, daily, weekly, or monthly. \n",
    "    #To measure recent volatility, use a shorter average, such as 2 to 10 periods. \n",
    "    #For longer-term volatility, use 20 to 50 periods.\n",
    "\n",
    "    ATR2 = ATR(fast_ma)\n",
    "        \n",
    "    final_fz = final_f.merge(ATR2, on='Date', how='left')\n",
    "    \n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # ADX average directional movement \n",
    "    #Wilder suggests that a strong trend is present when ADX is above 25 and no trend is present when below 20.\n",
    "    #If the ADX is declining, it could be an indication that the market is becoming less directional, and the current trend is weakening. You may want to avoid trading trend systems as the trend changes.\n",
    "    #If after staying low for a lengthy time, the ADX rises by 4 or 5 units, (for example, from 15 to 20), it may be giving a signal to trade the current trend.\n",
    "    # ADX AVERAGE DIRECTIONAL MOVEMENT\n",
    "    #https://www.investopedia.com/articles/trading/07/adx-trend-indicator.asp\n",
    "    # ADX values help traders identify the strongest and most profitable trends to trade. \n",
    "    #The values are also important for distinguishing between trending and non-trending conditions. \n",
    "    #Many traders will use ADX readings above 25 to suggest that the trend is strong enough for trend-trading strategies. \n",
    "    #Conversely, when ADX is below 25, many will avoid trend-trading strategies.\n",
    "\n",
    "    # ADX Value\tTrend Strength\n",
    "    # 0-25\tAbsent or Weak Trend\n",
    "    # 25-50\tStrong Trend\n",
    "    # 50-75\tVery Strong Trend\n",
    "    # 75-100\tExtremely Strong Trend\n",
    "    \n",
    "    final_fz['ADX'] = ADX(final_fz,slow_ma)\n",
    "    \n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    # Moving average convergence and divergence\n",
    "    #The Formula for MACD Is:\n",
    "    #MACD=12-Period EMA − 26-Period EMA\n",
    "\n",
    "    # KEY TAKEAWAYS\n",
    "    # Moving average convergence divergence (MACD) is calculated by subtracting the 26-period exponential moving average (EMA) from the 12-period EMA.\n",
    "    # MACD triggers technical signals when it crosses above (to buy) or below (to sell) its signal line.\n",
    "    # The speed of crossovers is also taken as a signal of a market is overbought or oversold.\n",
    "    # MACD helps investors understand whether the bullish or bearish movement in the price is strengthening or weakening.\n",
    "\n",
    "    # use typeical mcad values for now can change them later \n",
    "    \"\"\"function to calculate MACD\n",
    "       typical values a = 12; b =26, c =9\"\"\"\n",
    "    a = 12;b=26;c=9\n",
    "    MACD2 = MACD(final_fz, 12, 26, 9)\n",
    "    \n",
    "    \n",
    "    final_fz = final_f.merge(MACD2, on='Date', how='left')\n",
    "    return final_fz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "ETH-USD_percent_change\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETH_USD</th>\n",
       "      <th>ETH_USD_percent_change</th>\n",
       "      <th>ETH_USD_percent_change_shift</th>\n",
       "      <th>Position</th>\n",
       "      <th>Fast_moving_average</th>\n",
       "      <th>Slow_moving_average</th>\n",
       "      <th>BB_up</th>\n",
       "      <th>BB_dn</th>\n",
       "      <th>BB_width</th>\n",
       "      <th>RSI_slow</th>\n",
       "      <th>RSI_fast</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>10.506600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025403</td>\n",
       "      <td>10.506600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-14</th>\n",
       "      <td>10.239700</td>\n",
       "      <td>-0.025403</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>10.239700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-15</th>\n",
       "      <td>9.962350</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>0.121352</td>\n",
       "      <td>9.962350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-16</th>\n",
       "      <td>11.171300</td>\n",
       "      <td>0.121352</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>11.171300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-17</th>\n",
       "      <td>12.198800</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>12.198800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-07</th>\n",
       "      <td>3484.729004</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>0.119929</td>\n",
       "      <td>3484.728878</td>\n",
       "      <td>2043.469047</td>\n",
       "      <td>2585.728288</td>\n",
       "      <td>3008.879976</td>\n",
       "      <td>1078.058118</td>\n",
       "      <td>1930.821857</td>\n",
       "      <td>70.765898</td>\n",
       "      <td>65.985009</td>\n",
       "      <td>341.155349</td>\n",
       "      <td>263.121725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-08</th>\n",
       "      <td>3902.647705</td>\n",
       "      <td>0.119929</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>3902.647564</td>\n",
       "      <td>2068.895935</td>\n",
       "      <td>2646.197420</td>\n",
       "      <td>3105.654145</td>\n",
       "      <td>1032.137725</td>\n",
       "      <td>2073.516421</td>\n",
       "      <td>74.595807</td>\n",
       "      <td>68.270808</td>\n",
       "      <td>379.782124</td>\n",
       "      <td>286.453805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-09</th>\n",
       "      <td>3928.844727</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>3928.844584</td>\n",
       "      <td>2093.142912</td>\n",
       "      <td>2708.088615</td>\n",
       "      <td>3198.426263</td>\n",
       "      <td>987.859560</td>\n",
       "      <td>2210.566703</td>\n",
       "      <td>74.809571</td>\n",
       "      <td>68.405375</td>\n",
       "      <td>407.807056</td>\n",
       "      <td>310.724455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10</th>\n",
       "      <td>3952.293945</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.054755</td>\n",
       "      <td>3952.293802</td>\n",
       "      <td>2117.412455</td>\n",
       "      <td>2768.633675</td>\n",
       "      <td>3287.120689</td>\n",
       "      <td>947.704222</td>\n",
       "      <td>2339.416467</td>\n",
       "      <td>75.004114</td>\n",
       "      <td>68.526186</td>\n",
       "      <td>426.987131</td>\n",
       "      <td>333.976991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-11</th>\n",
       "      <td>4168.701172</td>\n",
       "      <td>0.054755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4168.701021</td>\n",
       "      <td>2144.350875</td>\n",
       "      <td>2835.668481</td>\n",
       "      <td>3387.788933</td>\n",
       "      <td>900.912816</td>\n",
       "      <td>2486.876117</td>\n",
       "      <td>76.718741</td>\n",
       "      <td>69.610508</td>\n",
       "      <td>454.411560</td>\n",
       "      <td>358.063904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ETH_USD  ETH_USD_percent_change  ETH_USD_percent_change_shift  \\\n",
       "Date                                                                            \n",
       "2016-05-13    10.506600                0.000000                     -0.025403   \n",
       "2016-05-14    10.239700               -0.025403                     -0.027086   \n",
       "2016-05-15     9.962350               -0.027086                      0.121352   \n",
       "2016-05-16    11.171300                0.121352                      0.091977   \n",
       "2016-05-17    12.198800                0.091977                      0.111470   \n",
       "...                 ...                     ...                           ...   \n",
       "2021-05-07  3484.729004               -0.001762                      0.119929   \n",
       "2021-05-08  3902.647705                0.119929                      0.006713   \n",
       "2021-05-09  3928.844727                0.006713                      0.005968   \n",
       "2021-05-10  3952.293945                0.005968                      0.054755   \n",
       "2021-05-11  4168.701172                0.054755                      0.000000   \n",
       "\n",
       "               Position  Fast_moving_average  Slow_moving_average  \\\n",
       "Date                                                                \n",
       "2016-05-13    10.506600                  NaN                  NaN   \n",
       "2016-05-14    10.239700                  NaN                  NaN   \n",
       "2016-05-15     9.962350                  NaN                  NaN   \n",
       "2016-05-16    11.171300                  NaN                  NaN   \n",
       "2016-05-17    12.198800                  NaN                  NaN   \n",
       "...                 ...                  ...                  ...   \n",
       "2021-05-07  3484.728878          2043.469047          2585.728288   \n",
       "2021-05-08  3902.647564          2068.895935          2646.197420   \n",
       "2021-05-09  3928.844584          2093.142912          2708.088615   \n",
       "2021-05-10  3952.293802          2117.412455          2768.633675   \n",
       "2021-05-11  4168.701021          2144.350875          2835.668481   \n",
       "\n",
       "                  BB_up        BB_dn     BB_width   RSI_slow   RSI_fast  \\\n",
       "Date                                                                      \n",
       "2016-05-13          NaN          NaN          NaN        NaN        NaN   \n",
       "2016-05-14          NaN          NaN          NaN        NaN        NaN   \n",
       "2016-05-15          NaN          NaN          NaN        NaN        NaN   \n",
       "2016-05-16          NaN          NaN          NaN        NaN        NaN   \n",
       "2016-05-17          NaN          NaN          NaN        NaN        NaN   \n",
       "...                 ...          ...          ...        ...        ...   \n",
       "2021-05-07  3008.879976  1078.058118  1930.821857  70.765898  65.985009   \n",
       "2021-05-08  3105.654145  1032.137725  2073.516421  74.595807  68.270808   \n",
       "2021-05-09  3198.426263   987.859560  2210.566703  74.809571  68.405375   \n",
       "2021-05-10  3287.120689   947.704222  2339.416467  75.004114  68.526186   \n",
       "2021-05-11  3387.788933   900.912816  2486.876117  76.718741  69.610508   \n",
       "\n",
       "                  MACD      Signal  \n",
       "Date                                \n",
       "2016-05-13         NaN         NaN  \n",
       "2016-05-14         NaN         NaN  \n",
       "2016-05-15         NaN         NaN  \n",
       "2016-05-16         NaN         NaN  \n",
       "2016-05-17         NaN         NaN  \n",
       "...                ...         ...  \n",
       "2021-05-07  341.155349  263.121725  \n",
       "2021-05-08  379.782124  286.453805  \n",
       "2021-05-09  407.807056  310.724455  \n",
       "2021-05-10  426.987131  333.976991  \n",
       "2021-05-11  454.411560  358.063904  \n",
       "\n",
       "[1821 rows x 13 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_f = single_stock_analyzer(stocks,beg_date,end_date,10.506600,30,90)\n",
    "final_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
